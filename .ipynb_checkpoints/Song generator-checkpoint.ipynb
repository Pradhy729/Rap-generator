{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])? y\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\pradhyum\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\matplotlib\\__init__.py:886: MatplotlibDeprecationWarning: \n",
      "examples.directory is deprecated; in the future, examples will be found relative to the 'datapath' directory.\n",
      "  \"found relative to the 'datapath' directory.\".format(key))\n"
     ]
    }
   ],
   "source": [
    "%reset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.style.use('fivethirtyeight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import tensorflow \n",
    "from tensorflow.keras.callbacks import LambdaCallback\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Dense, LSTM, Input, Dropout, Activation, TimeDistributed\n",
    "from tensorflow.keras.optimizers import RMSprop, Adam\n",
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "import io\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "from urllib.request import urlopen\n",
    "import urllib.request\n",
    "import re "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lyrics(artist,song_title):\n",
    "    artist = artist.lower()\n",
    "    song_title = song_title.lower()\n",
    "    # remove all except alphanumeric characters from artist and song_title\n",
    "    artist = re.sub('[^A-Za-z0-9]+', \"\", artist)\n",
    "    song_title = re.sub('[^A-Za-z0-9]+', \"\", song_title)\n",
    "    if artist.startswith(\"the\"):    # remove starting 'the' from artist e.g. the who -> who\n",
    "        artist = artist[3:]\n",
    "    url = \"http://azlyrics.com/lyrics/\"+artist+\"/\"+song_title+\".html\"\n",
    "    \n",
    "    try:\n",
    "        content = urllib.request.urlopen(url).read()\n",
    "        soup = BeautifulSoup(content, 'html.parser')\n",
    "        lyrics = str(soup)\n",
    "        # lyrics lies between up_partition and down_partition\n",
    "        up_partition = '<!-- Usage of azlyrics.com content by any third-party lyrics provider is prohibited by our licensing agreement. Sorry about that. -->'\n",
    "        down_partition = '<!-- MxM banner -->'\n",
    "        lyrics = lyrics.split(up_partition)[1]\n",
    "        lyrics = lyrics.split(down_partition)[0]\n",
    "        lyrics = lyrics.replace('<br>','').replace('</br>','').replace('</div>','').replace('<br/>','').strip()\n",
    "        return lyrics\n",
    "    except Exception as e:\n",
    "        return \"Exception occurred \\n\" +str(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_corpus(artist_name):\n",
    "    url = 'http://lyrics.wikia.com/wiki/' + artist_name\n",
    "    r = requests.get(url)\n",
    "    soup = BeautifulSoup(r.text, 'lxml')\n",
    "\n",
    "    count=0\n",
    "    data=[]\n",
    "\n",
    "    # Parse the data to get list of songs and urls\n",
    "    for album in soup.find_all(class_='album-art'):\n",
    "        count += 1\n",
    "        for song in album.find_next('ol').children:\n",
    "            try:\n",
    "                a = re.search('\\:(.*)', song.b.a['href'])\n",
    "                data.append({\n",
    "                    'url': song.b.a['href'],\n",
    "                    'name': a.group(1)\n",
    "                })\n",
    "            except:\n",
    "                continue\n",
    "    df = pd.DataFrame(data, columns=[\"url\",\"name\"])\n",
    "    print('Collecting {0} songs for {1}'.format(df.shape[0],artist_name))\n",
    "    corpus = ''\n",
    "    for ind, row in df.iterrows():\n",
    "        #print('Collecting song: {}'.format(row['name']))\n",
    "        corpus += '\\n' + get_lyrics(artist_name,row['name'])\n",
    "    print('Writing song corpus for {}'.format(artist_name))\n",
    "    with open(artist_name+\"_corpus.txt\", \"w\") as text_file:\n",
    "        text_file.write(corpus)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "artist_name = 'GOT'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_corpus_sequence(artist_name, level='word'):\n",
    "    from pathlib import Path\n",
    "    my_file = Path(artist_name+'_corpus.txt')\n",
    "    if not my_file.is_file():\n",
    "        print('Corpus doesn\\'t already exit for {}'.format(artist_name))\n",
    "        create_corpus(artist_name)\n",
    "    with open(artist_name+'_corpus.txt','r',encoding='utf8') as f:\n",
    "        print('Gathering and processing sequence or text')\n",
    "        try:\n",
    "            text = f.read().strip().lower().replace('\\n',' \\n ')\n",
    "        except:\n",
    "            text = f.read().encode('utf-8').strip().lower().replace('\\n',' \\n ')\n",
    "    if level =='word':\n",
    "        text_seq = [word for word in text.split(' ') if word.strip != '']\n",
    "    elif level=='char':\n",
    "        text_seq = [char for char in text]\n",
    "    return text_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gathering and processing sequence or text\n"
     ]
    }
   ],
   "source": [
    "text_seq = get_corpus_sequence(artist_name,level='word')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[first',\n",
       " 'scene',\n",
       " 'opens',\n",
       " 'with',\n",
       " 'three',\n",
       " 'rangers',\n",
       " 'riding',\n",
       " 'through',\n",
       " 'a',\n",
       " 'tunnel,',\n",
       " 'leaving',\n",
       " 'the',\n",
       " 'wall,',\n",
       " 'and',\n",
       " 'going',\n",
       " 'into',\n",
       " 'the',\n",
       " 'woods.',\n",
       " '(eerie',\n",
       " 'music',\n",
       " 'in',\n",
       " 'background)',\n",
       " 'one',\n",
       " 'ranger',\n",
       " 'splits',\n",
       " 'off',\n",
       " 'and',\n",
       " 'finds',\n",
       " 'a',\n",
       " 'campsite',\n",
       " 'full',\n",
       " 'of',\n",
       " 'mutilated',\n",
       " 'bodies,',\n",
       " 'including',\n",
       " 'a',\n",
       " 'child',\n",
       " 'hanging',\n",
       " 'from',\n",
       " 'a',\n",
       " 'tree',\n",
       " 'branch.',\n",
       " 'a',\n",
       " 'birds-eye',\n",
       " 'view',\n",
       " 'shows',\n",
       " 'the',\n",
       " 'bodies',\n",
       " 'arranged',\n",
       " 'in',\n",
       " 'a',\n",
       " 'shield-like',\n",
       " 'pattern.',\n",
       " 'the',\n",
       " 'ranger',\n",
       " 'rides',\n",
       " 'back',\n",
       " 'to',\n",
       " 'the',\n",
       " 'other',\n",
       " 'two.]',\n",
       " '\\n',\n",
       " 'waymar',\n",
       " 'royce:',\n",
       " 'what',\n",
       " 'd’you',\n",
       " 'expect?',\n",
       " 'they’re',\n",
       " 'savages.',\n",
       " 'one',\n",
       " 'lot',\n",
       " 'steals',\n",
       " 'a',\n",
       " 'goat',\n",
       " 'from',\n",
       " 'another',\n",
       " 'lot',\n",
       " 'and',\n",
       " 'before',\n",
       " 'you',\n",
       " 'know',\n",
       " 'it,',\n",
       " 'they’re',\n",
       " 'ripping',\n",
       " 'each',\n",
       " 'other',\n",
       " 'to',\n",
       " 'pieces.',\n",
       " '\\n',\n",
       " 'will:',\n",
       " 'i’ve',\n",
       " 'never',\n",
       " 'seen',\n",
       " 'wildlings',\n",
       " 'do',\n",
       " 'a',\n",
       " 'thing',\n",
       " 'like',\n",
       " 'this.',\n",
       " 'i’ve',\n",
       " 'never',\n",
       " 'seen',\n",
       " 'a',\n",
       " 'thing',\n",
       " 'like',\n",
       " 'this,',\n",
       " 'not',\n",
       " 'ever',\n",
       " 'in',\n",
       " 'my',\n",
       " 'life.',\n",
       " '\\n',\n",
       " 'waymar',\n",
       " 'royce:',\n",
       " 'how',\n",
       " 'close',\n",
       " 'did',\n",
       " 'you',\n",
       " 'get?',\n",
       " '\\n',\n",
       " 'will:',\n",
       " 'close',\n",
       " 'as',\n",
       " 'any',\n",
       " 'man',\n",
       " 'would.',\n",
       " '\\n',\n",
       " 'gared:',\n",
       " 'we',\n",
       " 'should',\n",
       " 'head',\n",
       " 'back',\n",
       " 'to',\n",
       " 'the',\n",
       " 'wall.',\n",
       " '\\n',\n",
       " 'royce:',\n",
       " 'do',\n",
       " 'the',\n",
       " 'dead',\n",
       " 'frighten',\n",
       " 'you?',\n",
       " '\\n',\n",
       " 'gared:',\n",
       " 'our',\n",
       " 'orders',\n",
       " 'were',\n",
       " 'to',\n",
       " 'track',\n",
       " 'the',\n",
       " 'wildlings.',\n",
       " 'we',\n",
       " 'tracked',\n",
       " 'them.',\n",
       " 'they',\n",
       " 'won’t',\n",
       " 'trouble',\n",
       " 'us',\n",
       " 'no',\n",
       " 'more.',\n",
       " '\\n',\n",
       " 'royce:',\n",
       " 'you',\n",
       " 'don’t',\n",
       " 'think',\n",
       " 'he’ll',\n",
       " 'ask',\n",
       " 'us',\n",
       " 'how',\n",
       " 'they',\n",
       " 'died?',\n",
       " 'get',\n",
       " 'back',\n",
       " 'on',\n",
       " 'your',\n",
       " 'horse.',\n",
       " '\\n',\n",
       " '[gared',\n",
       " 'grumbles.]',\n",
       " '\\n',\n",
       " 'will:',\n",
       " 'whatever',\n",
       " 'did',\n",
       " 'it',\n",
       " 'to',\n",
       " 'them',\n",
       " 'could',\n",
       " 'do',\n",
       " 'it',\n",
       " 'to',\n",
       " 'us.',\n",
       " 'they',\n",
       " 'even',\n",
       " 'killed',\n",
       " 'the',\n",
       " 'children.',\n",
       " '\\n',\n",
       " 'royce:',\n",
       " 'it’s',\n",
       " 'a',\n",
       " 'good',\n",
       " 'thing',\n",
       " 'we’re',\n",
       " 'not',\n",
       " 'children.',\n",
       " 'you',\n",
       " 'want',\n",
       " 'to',\n",
       " 'run',\n",
       " 'away',\n",
       " 'south,',\n",
       " 'run',\n",
       " 'away.',\n",
       " 'of',\n",
       " 'course,',\n",
       " 'they',\n",
       " 'will',\n",
       " 'behead',\n",
       " 'you',\n",
       " 'as',\n",
       " 'a',\n",
       " 'deserter',\n",
       " '…',\n",
       " 'if',\n",
       " 'i',\n",
       " 'don’t',\n",
       " 'catch',\n",
       " 'you',\n",
       " 'first.',\n",
       " 'get',\n",
       " 'back',\n",
       " 'on',\n",
       " 'your',\n",
       " 'horse.',\n",
       " 'i',\n",
       " 'won’t',\n",
       " 'say',\n",
       " 'it',\n",
       " 'again.',\n",
       " '\\n',\n",
       " '[will',\n",
       " 'glares,',\n",
       " 'but',\n",
       " 'obeys.',\n",
       " 'sometime',\n",
       " 'later,',\n",
       " 'the',\n",
       " 'three',\n",
       " 'rangers',\n",
       " 'return',\n",
       " 'to',\n",
       " 'the',\n",
       " 'campsite,',\n",
       " 'which',\n",
       " 'is',\n",
       " 'now',\n",
       " 'completely',\n",
       " 'cleared.]',\n",
       " '\\n',\n",
       " 'royce:',\n",
       " 'your',\n",
       " 'dead',\n",
       " 'men',\n",
       " 'seem',\n",
       " 'to',\n",
       " 'have',\n",
       " 'moved',\n",
       " 'camp.',\n",
       " '\\n',\n",
       " 'will:',\n",
       " 'they',\n",
       " 'were',\n",
       " 'here.',\n",
       " '\\n',\n",
       " 'gared:',\n",
       " 'see',\n",
       " 'where',\n",
       " 'they',\n",
       " 'went.',\n",
       " '\\n',\n",
       " '[the',\n",
       " 'three',\n",
       " 'look',\n",
       " 'around,',\n",
       " 'swords',\n",
       " 'drawn.',\n",
       " 'they',\n",
       " 'hear',\n",
       " 'the',\n",
       " 'wind',\n",
       " 'and',\n",
       " 'eerie',\n",
       " 'calls.',\n",
       " 'gared',\n",
       " 'finds',\n",
       " 'a',\n",
       " 'red',\n",
       " 'cloth',\n",
       " 'in',\n",
       " 'the',\n",
       " 'snow.]',\n",
       " '\\n',\n",
       " 'royce:',\n",
       " 'what',\n",
       " 'is',\n",
       " 'it?',\n",
       " '\\n',\n",
       " 'gared:',\n",
       " 'it’s',\n",
       " '…',\n",
       " '\\n',\n",
       " '[as',\n",
       " 'he',\n",
       " 'speaks,',\n",
       " 'a',\n",
       " 'creature',\n",
       " 'with',\n",
       " 'glowing',\n",
       " 'blue',\n",
       " 'eyes',\n",
       " 'rises',\n",
       " 'behind',\n",
       " 'royce.',\n",
       " 'royce',\n",
       " 'turns,',\n",
       " 'the',\n",
       " 'creature',\n",
       " 'strikes.',\n",
       " 'the',\n",
       " 'scene',\n",
       " 'shifts',\n",
       " 'to',\n",
       " 'will,',\n",
       " 'who',\n",
       " 'hears',\n",
       " 'a',\n",
       " 'man',\n",
       " 'crying',\n",
       " 'out.',\n",
       " 'the',\n",
       " 'three',\n",
       " 'horses',\n",
       " 'stampede',\n",
       " 'past',\n",
       " 'him.',\n",
       " 'he',\n",
       " 'turns',\n",
       " 'and',\n",
       " 'sees',\n",
       " 'someone',\n",
       " 'standing',\n",
       " 'very',\n",
       " 'still',\n",
       " 'in',\n",
       " 'the',\n",
       " 'distance.',\n",
       " 'the',\n",
       " 'figure',\n",
       " 'turns',\n",
       " '–',\n",
       " 'it’s',\n",
       " 'the',\n",
       " 'child',\n",
       " 'who',\n",
       " 'had',\n",
       " 'been',\n",
       " 'suspended',\n",
       " 'in',\n",
       " 'the',\n",
       " 'tree,',\n",
       " 'now',\n",
       " 'with',\n",
       " 'glowing',\n",
       " 'blue',\n",
       " 'eyes.',\n",
       " 'will',\n",
       " 'turns',\n",
       " 'and',\n",
       " 'runs.',\n",
       " '\\n',\n",
       " 'gared',\n",
       " 'is',\n",
       " 'also',\n",
       " 'fleeing,',\n",
       " 'and',\n",
       " 'we',\n",
       " 'hear',\n",
       " 'strange',\n",
       " 'growls',\n",
       " 'and',\n",
       " 'catch',\n",
       " 'glimpses',\n",
       " 'of',\n",
       " 'the',\n",
       " 'creature.',\n",
       " 'both',\n",
       " 'terrified',\n",
       " 'rangers',\n",
       " 'stop,',\n",
       " 'some',\n",
       " 'distance',\n",
       " 'apart,',\n",
       " 'to',\n",
       " 'catch',\n",
       " 'their',\n",
       " 'breath.',\n",
       " 'will',\n",
       " 'sees',\n",
       " 'a',\n",
       " 'creature',\n",
       " 'behead',\n",
       " 'gared.',\n",
       " 'will',\n",
       " 'sinks',\n",
       " 'to',\n",
       " 'his',\n",
       " 'knees',\n",
       " 'and',\n",
       " 'the',\n",
       " 'creature',\n",
       " 'tosses',\n",
       " 'gared’s',\n",
       " 'head',\n",
       " 'to',\n",
       " 'him.]',\n",
       " '\\n',\n",
       " '[blackout]',\n",
       " '\\n',\n",
       " 'title',\n",
       " 'sequence[riders',\n",
       " 'from',\n",
       " 'winterfell',\n",
       " 'come',\n",
       " 'up',\n",
       " 'behind',\n",
       " 'a',\n",
       " 'dazed',\n",
       " 'will.',\n",
       " 'the',\n",
       " 'scene',\n",
       " 'shifts',\n",
       " 'to',\n",
       " 'the',\n",
       " 'castle,',\n",
       " 'where',\n",
       " 'bran',\n",
       " 'is',\n",
       " 'practicing',\n",
       " 'archery',\n",
       " 'and',\n",
       " 'getting',\n",
       " 'frustrated,',\n",
       " 'under',\n",
       " 'the',\n",
       " 'eyes',\n",
       " 'of',\n",
       " 'jon',\n",
       " 'snow',\n",
       " 'and',\n",
       " 'robb',\n",
       " 'stark.',\n",
       " 'jon',\n",
       " 'pats',\n",
       " 'bran’s',\n",
       " 'shoulder.]',\n",
       " '\\n',\n",
       " 'jon:',\n",
       " 'go',\n",
       " 'on.',\n",
       " 'father’s',\n",
       " 'watching.',\n",
       " '\\n',\n",
       " '[we',\n",
       " 'see',\n",
       " 'ned',\n",
       " 'and',\n",
       " 'catelyn',\n",
       " 'stark',\n",
       " 'watching',\n",
       " 'from',\n",
       " 'above.]',\n",
       " '\\n',\n",
       " 'jon:',\n",
       " 'and',\n",
       " 'your',\n",
       " 'mother.',\n",
       " '\\n',\n",
       " '[scene',\n",
       " 'shifts',\n",
       " 'to',\n",
       " 'needlework',\n",
       " 'practice',\n",
       " 'with',\n",
       " 'the',\n",
       " 'girls',\n",
       " 'inside',\n",
       " 'the',\n",
       " 'castle.]',\n",
       " '\\n',\n",
       " 'septa',\n",
       " 'mordane',\n",
       " '(to',\n",
       " 'sansa):',\n",
       " 'fine',\n",
       " 'work,',\n",
       " 'as',\n",
       " 'always.',\n",
       " 'well',\n",
       " 'done.',\n",
       " '\\n',\n",
       " 'sansa:',\n",
       " 'thank',\n",
       " 'you.',\n",
       " '\\n',\n",
       " 'septa',\n",
       " 'mordane:',\n",
       " 'i',\n",
       " 'love',\n",
       " 'the',\n",
       " 'detail',\n",
       " 'that',\n",
       " 'you’ve',\n",
       " 'managed',\n",
       " 'to',\n",
       " 'get',\n",
       " 'in',\n",
       " 'this',\n",
       " 'corners.',\n",
       " '…',\n",
       " 'quite',\n",
       " 'beautiful',\n",
       " '…',\n",
       " 'the',\n",
       " 'stitching',\n",
       " '…',\n",
       " '\\n',\n",
       " '[as',\n",
       " 'she',\n",
       " 'murmurs',\n",
       " 'to',\n",
       " 'sansa',\n",
       " 'about',\n",
       " 'the',\n",
       " 'embroidery,',\n",
       " 'arya',\n",
       " 'struggles',\n",
       " 'with',\n",
       " 'her',\n",
       " 'needlework',\n",
       " 'and',\n",
       " 'listens',\n",
       " 'to',\n",
       " 'the',\n",
       " 'arrows',\n",
       " 'hitting',\n",
       " 'and',\n",
       " 'the',\n",
       " 'male',\n",
       " 'laughter',\n",
       " 'outside.]',\n",
       " '\\n',\n",
       " '[outside,',\n",
       " 'bran',\n",
       " 'tries',\n",
       " 'and',\n",
       " 'misses',\n",
       " 'again.',\n",
       " 'everyone',\n",
       " 'laughs.]',\n",
       " '\\n',\n",
       " 'ned:',\n",
       " 'and',\n",
       " 'which',\n",
       " 'one',\n",
       " 'of',\n",
       " 'you',\n",
       " 'was',\n",
       " 'a',\n",
       " 'marksman',\n",
       " 'at',\n",
       " 'ten?',\n",
       " 'keep',\n",
       " 'practicing,',\n",
       " 'bran.',\n",
       " 'go',\n",
       " 'on.',\n",
       " '\\n',\n",
       " 'jon:',\n",
       " 'don’t',\n",
       " 'think',\n",
       " 'too',\n",
       " 'much,',\n",
       " 'bran.',\n",
       " '\\n',\n",
       " 'robb:',\n",
       " 'relax',\n",
       " 'your',\n",
       " 'bow',\n",
       " 'arm.',\n",
       " '\\n',\n",
       " '[bran',\n",
       " 'pulls',\n",
       " 'the',\n",
       " 'arrow',\n",
       " 'back.',\n",
       " 'an',\n",
       " 'arrow',\n",
       " 'hits',\n",
       " 'the',\n",
       " 'bullseye.',\n",
       " 'bran',\n",
       " '(still',\n",
       " 'with',\n",
       " 'his',\n",
       " 'arrow),',\n",
       " 'jon,',\n",
       " 'and',\n",
       " 'robb',\n",
       " 'turn',\n",
       " 'in',\n",
       " 'surprise',\n",
       " 'to',\n",
       " 'see',\n",
       " 'arya,',\n",
       " 'who',\n",
       " 'curtsies',\n",
       " 'after',\n",
       " 'her',\n",
       " 'perfect',\n",
       " 'shot.',\n",
       " 'robb',\n",
       " 'and',\n",
       " 'jon',\n",
       " 'laugh',\n",
       " 'as',\n",
       " 'bran',\n",
       " 'takes',\n",
       " 'out',\n",
       " 'after',\n",
       " 'arya.]',\n",
       " '\\n',\n",
       " 'jon/robb:',\n",
       " 'quick,',\n",
       " 'bran,',\n",
       " 'faster!',\n",
       " '\\n',\n",
       " '[rodrick',\n",
       " 'cassel',\n",
       " 'and',\n",
       " 'theon',\n",
       " 'greyjoy',\n",
       " 'approach',\n",
       " 'ned',\n",
       " 'and',\n",
       " 'catelyn',\n",
       " 'on',\n",
       " 'the',\n",
       " 'balcony.]',\n",
       " '\\n',\n",
       " 'cassel:',\n",
       " 'lord',\n",
       " 'stark.',\n",
       " 'my',\n",
       " 'lady.',\n",
       " 'a',\n",
       " 'guardsman',\n",
       " 'just',\n",
       " 'rode',\n",
       " 'in',\n",
       " 'from',\n",
       " 'the',\n",
       " 'hills.',\n",
       " 'they’ve',\n",
       " 'captured',\n",
       " 'a',\n",
       " 'deserter',\n",
       " 'from',\n",
       " 'the',\n",
       " 'night’s',\n",
       " 'watch.',\n",
       " '\\n',\n",
       " '[ned',\n",
       " 'grimaces.]',\n",
       " '\\n',\n",
       " 'ned:',\n",
       " 'get',\n",
       " 'the',\n",
       " 'lads',\n",
       " 'to',\n",
       " 'saddle',\n",
       " 'their',\n",
       " 'horses.',\n",
       " '\\n',\n",
       " '[theon',\n",
       " 'departs.]',\n",
       " '\\n',\n",
       " 'catelyn:',\n",
       " 'do',\n",
       " 'you',\n",
       " 'have',\n",
       " 'to?',\n",
       " '\\n',\n",
       " 'ned:',\n",
       " 'he',\n",
       " 'swore',\n",
       " 'an',\n",
       " 'oath,',\n",
       " 'cat.',\n",
       " '\\n',\n",
       " 'cassel:',\n",
       " 'the',\n",
       " 'law',\n",
       " 'is',\n",
       " 'law,',\n",
       " 'my',\n",
       " 'lady.',\n",
       " '\\n',\n",
       " 'ned:',\n",
       " 'tell',\n",
       " 'bran',\n",
       " 'he’s',\n",
       " 'coming,',\n",
       " 'too.',\n",
       " '\\n',\n",
       " '[cassel',\n",
       " 'nods',\n",
       " 'and',\n",
       " 'departs.]',\n",
       " '\\n',\n",
       " 'catelyn:',\n",
       " 'ned.',\n",
       " 'ten',\n",
       " 'is',\n",
       " 'too',\n",
       " 'young',\n",
       " 'to',\n",
       " 'see',\n",
       " 'such',\n",
       " 'things.',\n",
       " '\\n',\n",
       " 'ned:',\n",
       " 'he',\n",
       " 'won’t',\n",
       " 'be',\n",
       " 'a',\n",
       " 'boy',\n",
       " 'forever.',\n",
       " 'and',\n",
       " 'winter',\n",
       " 'is',\n",
       " 'coming.',\n",
       " '\\n',\n",
       " '[ned',\n",
       " 'departs.',\n",
       " 'in',\n",
       " 'the',\n",
       " 'courtyard,',\n",
       " 'robb',\n",
       " 'and',\n",
       " 'jon',\n",
       " 'gather',\n",
       " 'the',\n",
       " 'arrows.',\n",
       " 'catelyn',\n",
       " 'turns',\n",
       " 'and',\n",
       " 'glares',\n",
       " 'down',\n",
       " 'on',\n",
       " 'jon.',\n",
       " 'he',\n",
       " 'looks',\n",
       " 'at',\n",
       " 'her',\n",
       " 'and',\n",
       " 'walks',\n",
       " 'away.]',\n",
       " '\\n',\n",
       " 'robb:',\n",
       " 'lad,',\n",
       " 'go',\n",
       " 'run',\n",
       " 'back',\n",
       " 'and',\n",
       " 'get',\n",
       " 'the',\n",
       " 'rest.',\n",
       " '\\n',\n",
       " '[scene',\n",
       " 'shifts,',\n",
       " 'and',\n",
       " 'we',\n",
       " 'see',\n",
       " 'will',\n",
       " 'being',\n",
       " 'taken',\n",
       " 'to',\n",
       " 'the',\n",
       " 'block.]',\n",
       " '\\n',\n",
       " 'will',\n",
       " '(muttering):',\n",
       " 'white',\n",
       " 'walkers.',\n",
       " 'i',\n",
       " 'saw',\n",
       " 'the',\n",
       " 'white',\n",
       " 'walkers.',\n",
       " 'white',\n",
       " 'walkers.',\n",
       " 'the',\n",
       " 'white',\n",
       " 'walkers,',\n",
       " 'i',\n",
       " 'saw',\n",
       " 'them.',\n",
       " '\\n',\n",
       " '[he',\n",
       " 'and',\n",
       " 'ned',\n",
       " 'face',\n",
       " 'each',\n",
       " 'other.]',\n",
       " '\\n',\n",
       " 'will:',\n",
       " 'i',\n",
       " 'know',\n",
       " 'i',\n",
       " 'broke',\n",
       " 'my',\n",
       " 'oath.',\n",
       " 'and',\n",
       " 'i',\n",
       " 'know',\n",
       " 'i’m',\n",
       " 'a',\n",
       " 'deserter.',\n",
       " 'i',\n",
       " 'should',\n",
       " 'have',\n",
       " 'gone',\n",
       " 'back',\n",
       " 'to',\n",
       " 'the',\n",
       " 'wall',\n",
       " 'and',\n",
       " 'warned',\n",
       " 'them.',\n",
       " 'but',\n",
       " 'i',\n",
       " 'saw',\n",
       " 'what',\n",
       " 'i',\n",
       " 'saw.',\n",
       " 'i',\n",
       " 'saw',\n",
       " 'the',\n",
       " 'white',\n",
       " 'walkers.',\n",
       " 'people',\n",
       " 'need',\n",
       " 'to',\n",
       " 'know.',\n",
       " 'if',\n",
       " 'you',\n",
       " 'can',\n",
       " 'get',\n",
       " 'word',\n",
       " 'to',\n",
       " 'my',\n",
       " 'family,',\n",
       " 'tell',\n",
       " 'them',\n",
       " 'i’m',\n",
       " 'no',\n",
       " 'coward.',\n",
       " 'tell',\n",
       " 'them',\n",
       " 'i’m',\n",
       " 'sorry.',\n",
       " '\\n',\n",
       " 'ned',\n",
       " 'nods',\n",
       " 'yes,',\n",
       " 'and',\n",
       " 'will',\n",
       " 'is',\n",
       " 'positioned',\n",
       " 'on',\n",
       " 'the',\n",
       " 'tree',\n",
       " 'limb',\n",
       " 'that',\n",
       " 'serves',\n",
       " 'as',\n",
       " 'a',\n",
       " 'block.',\n",
       " '[ned',\n",
       " 'draws',\n",
       " 'ice',\n",
       " 'from',\n",
       " 'a',\n",
       " 'scabbard',\n",
       " 'held',\n",
       " 'by',\n",
       " 'theon.]',\n",
       " '\\n',\n",
       " 'will',\n",
       " '(whispering):',\n",
       " 'forgive',\n",
       " 'me,',\n",
       " 'lord.',\n",
       " '\\n',\n",
       " '[ned',\n",
       " 'bows',\n",
       " 'his',\n",
       " 'head',\n",
       " 'over',\n",
       " 'ice.]',\n",
       " '\\n',\n",
       " 'ned:',\n",
       " 'in',\n",
       " 'the',\n",
       " 'name',\n",
       " 'of',\n",
       " 'robert',\n",
       " 'of',\n",
       " 'the',\n",
       " 'house',\n",
       " 'baratheon,',\n",
       " 'first',\n",
       " 'of',\n",
       " 'his',\n",
       " 'name',\n",
       " '…',\n",
       " '\\n',\n",
       " 'jon',\n",
       " '(to',\n",
       " 'bran):',\n",
       " 'don’t',\n",
       " 'look',\n",
       " 'away.',\n",
       " '\\n',\n",
       " 'ned:',\n",
       " 'king',\n",
       " 'of',\n",
       " 'the',\n",
       " 'andals',\n",
       " 'and',\n",
       " 'the',\n",
       " 'first',\n",
       " 'men',\n",
       " '…',\n",
       " '\\n',\n",
       " 'jon:',\n",
       " 'father',\n",
       " 'will',\n",
       " 'know',\n",
       " 'if',\n",
       " 'you',\n",
       " 'do.',\n",
       " '\\n',\n",
       " 'ned:',\n",
       " 'lord',\n",
       " 'of',\n",
       " 'the',\n",
       " 'seven',\n",
       " 'kingdoms',\n",
       " 'and',\n",
       " 'protector',\n",
       " 'of',\n",
       " 'the',\n",
       " 'realm,',\n",
       " 'i,',\n",
       " 'eddard',\n",
       " 'of',\n",
       " 'the',\n",
       " 'house',\n",
       " 'stark,',\n",
       " 'lord',\n",
       " 'of',\n",
       " 'winterfell',\n",
       " 'and',\n",
       " 'warden',\n",
       " 'of',\n",
       " 'the',\n",
       " 'north,',\n",
       " 'sentence',\n",
       " 'you',\n",
       " 'to',\n",
       " 'die.',\n",
       " '\\n',\n",
       " '[ned',\n",
       " 'swings',\n",
       " 'ice',\n",
       " 'and',\n",
       " 'beheads',\n",
       " 'will.',\n",
       " 'bran',\n",
       " ...]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique words before ignoring: 25980\n",
      "Ignoring words with frequency < 3\n",
      "Unique words after ignoring: 10080\n"
     ]
    }
   ],
   "source": [
    "# Calculate word frequency\n",
    "word_freq = {}\n",
    "for word in text_seq:\n",
    "    word_freq[word] = word_freq.get(word, 0) + 1\n",
    "MIN_WORD_FREQUENCY = 3\n",
    "ignored_words = set()\n",
    "for k, v in word_freq.items():\n",
    "    if word_freq[k] < MIN_WORD_FREQUENCY:\n",
    "        ignored_words.add(k)\n",
    "\n",
    "words = set(text_seq)\n",
    "print('Unique words before ignoring:', len(words))\n",
    "print('Ignoring words with frequency <', MIN_WORD_FREQUENCY)\n",
    "words = sorted(set(words) - ignored_words)\n",
    "print('Unique words after ignoring:', len(words))\n",
    "\n",
    "text_seq = [word for word in text_seq if word not in ignored_words]\n",
    "word_indices = dict((c, i) for i, c in enumerate(words))\n",
    "indices_word = dict((i, c) for i, c in enumerate(words))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ignored sequences: 0\n",
      "Remaining sequences: 467774\n",
      "Randome sentence: on the that he passed out on\n",
      "Corresponding next words: ['the']\n"
     ]
    }
   ],
   "source": [
    "# cut the text in semi-redundant sequences of SEQUENCE_LEN words\n",
    "INPUT_SEQUENCE_LEN = 7\n",
    "OUTPUT_SEQUENCE_LEN = 1\n",
    "STEP = OUTPUT_SEQUENCE_LEN\n",
    "sentences = []\n",
    "next_words = []\n",
    "ignored = 0\n",
    "for i in range(0, len(text_seq) - INPUT_SEQUENCE_LEN, STEP):\n",
    "    # Only add sequences where no word is in ignored_words\n",
    "    if len(set(text_seq[i: i+INPUT_SEQUENCE_LEN+1]).intersection(ignored_words)) == 0:\n",
    "        sentences.append(text_seq[i: i + INPUT_SEQUENCE_LEN])\n",
    "        next_words.append(text_seq[i + INPUT_SEQUENCE_LEN:i + INPUT_SEQUENCE_LEN + OUTPUT_SEQUENCE_LEN ])\n",
    "    else:\n",
    "        ignored = ignored+1\n",
    "print('Ignored sequences:', ignored)\n",
    "print('Remaining sequences:', len(sentences))\n",
    "rand_index = np.random.randint(0,len(sentences))\n",
    "print('Randome sentence: {}'.format(' '.join(sentences[rand_index])))\n",
    "print('Corresponding next words: {}'.format(next_words[rand_index]))\n",
    "sentences = sentences[:10000]\n",
    "next_words = next_words[:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class seqSentenceGenerator(tensorflow.keras.utils.Sequence):\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self, sentences=sentences, next_words=next_words,word_indices=word_indices, indices_word=indices_word, batch_size=64, shuffle=True):\n",
    "        'Initialization'\n",
    "        self.dim = (len(sentences),INPUT_SEQUENCE_LEN,len(words))\n",
    "        self.sentences = sentences\n",
    "        self.next_words = next_words\n",
    "        self.word_indices = word_indices\n",
    "        self.indices_word = indices_word\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return self.dim[0]//self.batch_size\n",
    "\n",
    "    def __getitem__(self, index, seq2seq=False):\n",
    "        'Generate one batch of data'\n",
    "        # Generate data\n",
    "        X, y = next(self.__data_generation(self.sentences,self.next_words))\n",
    "        return X, y\n",
    "\n",
    "    '''def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(len(self.list_IDs))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)'''\n",
    "            \n",
    "    def __data_generation(self, sentences, next_words):\n",
    "        for i, sentence in enumerate(sentences):\n",
    "            x = np.zeros((1,INPUT_SEQUENCE_LEN, len(words)), dtype=np.int8)\n",
    "            y = np.zeros((1,INPUT_SEQUENCE_LEN, len(words)), dtype=np.int8)\n",
    "            for tx, word in enumerate(sentence):\n",
    "                x[0, tx, self.word_indices[word]] = 1\n",
    "            for ty, word in enumerate(next_words[i]):\n",
    "                y[0, ty, self.word_indices[word]] = 1\n",
    "            yield x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentenceGenerator(tensorflow.keras.utils.Sequence):\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self, sentences=sentences, next_words=next_words,word_indices=word_indices, indices_word=indices_word, batch_size=64, shuffle=True, INPUT_SEQUENCE_LEN=INPUT_SEQUENCE_LEN):\n",
    "        'Initialization'\n",
    "        self.dim = (len(sentences),INPUT_SEQUENCE_LEN,len(words))\n",
    "        self.sentences = sentences\n",
    "        self.next_words = next_words\n",
    "        self.word_indices = word_indices\n",
    "        self.indices_word = indices_word\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return self.dim[0]//self.batch_size\n",
    "\n",
    "    def __getitem__(self, index, seq2seq=False):\n",
    "        'Generate one batch of data'\n",
    "        # Generate data\n",
    "        X, y = next(self.__data_generation(self.sentences,self.next_words))\n",
    "        return X, y\n",
    "    \n",
    "    def __data_generation(self, sentences, next_words):\n",
    "        for i, sentence in enumerate(sentences):\n",
    "            X_ngram = np.zeros((1,INPUT_SEQUENCE_LEN, len(words)), dtype=np.int8)\n",
    "            y_ngram = np.zeros((1, len(words)), dtype=np.int8)\n",
    "            for tx, word in enumerate(sentence):\n",
    "                X_ngram[i, tx, self.word_indices[word]] = 1\n",
    "            y_ngram[i, self.word_indices[word]] = 1\n",
    "            yield X_ngram, y_ngram\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ngram = np.zeros((len(sentences),INPUT_SEQUENCE_LEN, len(words)), dtype=np.int8)\n",
    "y_ngram = np.zeros((len(sentences), len(words)), dtype=np.int8)\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for tx, word in enumerate(sentence):\n",
    "        X_ngram[i, tx, word_indices[word]] = 1\n",
    "    y_ngram[i, word_indices[word]] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the model: a single LSTM\n",
    "def create_model(seq2seq=True, enc_dec_attention=False):\n",
    "    print('Build model...')\n",
    "    if seq2seq:\n",
    "        inputs = Input(shape=(INPUT_SEQUENCE_LEN,len(words)))\n",
    "        encoder = LSTM(units=128, return_sequences=True, name='encoder_LSTM', dropout=0.5)(inputs)\n",
    "        decoder = LSTM(units=128, return_sequences=True, name='decoder_LSTM', dropout=0.5)(encoder)\n",
    "        if not enc_dec_attention:\n",
    "            outputs = TimeDistributed(Dense(len(words), activation='softmax', name='Time Distributed Dense'))(decoder)\n",
    "        else:\n",
    "            context = tensorflow.keras.layers.Attention(name='attention')([decoder,encoder])\n",
    "            concatenated = tensorflow.keras.layers.Concatenate(name='concatenate_attention')([context,decoder])\n",
    "            outputs = TimeDistributed(Dense(len(words), activation='softmax'))(concatenated)\n",
    "\n",
    "        model = Model(inputs=inputs,outputs=outputs)\n",
    "        return model\n",
    "    else:\n",
    "        inputs = Input(shape=(INPUT_SEQUENCE_LEN,len(words)))\n",
    "        encoder = tensorflow.keras.layers.Bidirectional(LSTM(units=128, return_sequences=False, name='encoder_LSTM', dropout=0.5))(inputs)\n",
    "        outputs = Dense(len(words), activation='softmax')(encoder)\n",
    "        model = Model(inputs=inputs, outputs=outputs)\n",
    "        return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 7, 10080)]        0         \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 256)               10454016  \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10080)             2590560   \n",
      "=================================================================\n",
      "Total params: 13,044,576\n",
      "Trainable params: 13,044,576\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.core.protobuf import rewriter_config_pb2\n",
    "from tensorflow.keras.backend import set_session\n",
    "tensorflow.keras.backend.clear_session()  # For easy reset of notebook state.\n",
    "\n",
    "config_proto = tensorflow.ConfigProto()\n",
    "off = rewriter_config_pb2.RewriterConfig.OFF\n",
    "config_proto.graph_options.rewrite_options.arithmetic_optimization = off\n",
    "session = tensorflow.Session(config=config_proto)\n",
    "set_session(session)\n",
    "model = create_model(seq2seq=False,enc_dec_attention=True)\n",
    "from tensorflow.keras.optimizers import RMSprop, Adam\n",
    "model.compile(loss='categorical_crossentropy', optimizer=RMSprop(), metrics=['acc'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use genrator to create batches of training examples to train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(preds, seq2seq=False, temperature=1.0):\n",
    "    # helper function to sample an index from a probability array\n",
    "    if not seq2seq:\n",
    "        preds = np.asarray(preds).astype('float64')\n",
    "        preds = np.log(preds) / temperature\n",
    "        exp_preds = np.exp(preds)\n",
    "        preds = exp_preds / np.sum(exp_preds)\n",
    "        probas = np.random.multinomial(1, preds, 1)\n",
    "        return np.argmax(probas)\n",
    "    else:\n",
    "        samples = []\n",
    "        for i in range(OUTPUT_SEQUENCE_LEN):\n",
    "            preds = preds_orig[0,i,:].astype('float64')\n",
    "            preds = np.log(preds) / temperature\n",
    "            exp_preds = np.exp(preds)\n",
    "            preds = exp_preds / np.sum(exp_preds)\n",
    "            samples.append(np.argmax(np.random.multinomial(1,preds,1)))\n",
    "        return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def on_epoch_end(epoch, _):\n",
    "    # Function invoked at end of each epoch. Prints generated text.\n",
    "    if epoch%1 == 0:\n",
    "        print()\n",
    "        print('----- Generating text after Epoch: %d' % epoch)\n",
    "\n",
    "        start_index = random.randint(0, len(text_seq) - INPUT_SEQUENCE_LEN - 1)\n",
    "        generated = ''\n",
    "        sentence = ' '.join(text_seq[start_index: start_index + INPUT_SEQUENCE_LEN])\n",
    "        generated += sentence\n",
    "        print('----- Generating with seed: \"' + sentence + '\"')\n",
    "        sys.stdout.write(generated)\n",
    "\n",
    "        for i in range(0,50, STEP):\n",
    "            x_pred = np.zeros((1, INPUT_SEQUENCE_LEN, len(words)))\n",
    "            for t, word in enumerate(sentence.split(' ')):\n",
    "                x_pred[0, t, word_indices[word]] = 1.\n",
    "            #print('Here the sentence is {}'.format(sentence))\n",
    "\n",
    "            preds = model.predict(x_pred)\n",
    "            next_indices = sample(preds, temperature=1.0)\n",
    "            try:\n",
    "                next_words = ' '.join([indices_word[ind] for ind in next_indices])\n",
    "            except:\n",
    "                next_words = indices_word[next_indices]\n",
    "            sentence = ' '.join(sentence.split(' ')[STEP:])+ ' ' +next_words\n",
    "            #print('After appending next word the sentence is: {}'.format(sentence))\n",
    "            sys.stdout.write(' ' + next_words)\n",
    "            sys.stdout.flush()\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_callback = LambdaCallback(on_epoch_end=on_epoch_end)\n",
    "weights_seq_output = np.zeros((INPUT_SEQUENCE_LEN,len(words)))\n",
    "weights_seq_output[range(OUTPUT_SEQUENCE_LEN),:] = 1\n",
    "model_history = model.fit_generator(generator=SentenceGenerator(),\n",
    "                                    epochs=1,\n",
    "                                    callbacks=[print_callback],\n",
    "                                    class_weight=weights_seq_output,\n",
    "                                    use_multiprocessing=False,\n",
    "                                    max_queue_size=4,\n",
    "                                    workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\pradhyum\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow_core\\python\\ops\\math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Train on 10000 samples\n",
      "Epoch 1/10\n",
      " 9984/10000 [============================>.] - ETA: 0s - loss: 6.8613 - acc: 0.0718\n",
      "----- Generating text after Epoch: 0\n",
      "----- Generating with seed: \"to be ned’s quarters. he opens his\"\n",
      "to be ned’s quarters. he opens his"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'numpy.int64' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-df49c511b89c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mprint_callback\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLambdaCallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmodel_history\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_ngram\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_ngram\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mprint_callback\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\pradhyum\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    728\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    729\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32mc:\\users\\pradhyum\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[0;32m    673\u001b[0m         \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    674\u001b[0m         \u001b[0mvalidation_freq\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_freq\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 675\u001b[1;33m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[0;32m    676\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    677\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32mc:\\users\\pradhyum\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[1;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[0;32m    448\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    449\u001b[0m       \u001b[1;31m# Epochs only apply to `fit`.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 450\u001b[1;33m       \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    451\u001b[0m     \u001b[0mprogbar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    452\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\pradhyum\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow_core\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36mon_epoch_end\u001b[1;34m(self, epoch, logs)\u001b[0m\n\u001b[0;32m    297\u001b[0m     \u001b[0mlogs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlogs\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    298\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 299\u001b[1;33m       \u001b[0mcallback\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    300\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    301\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-26-20b7e76913a6>\u001b[0m in \u001b[0;36mon_epoch_end\u001b[1;34m(epoch, _)\u001b[0m\n\u001b[0;32m     20\u001b[0m             \u001b[0mpreds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m             \u001b[0mnext_indices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtemperature\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1.0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m             \u001b[0mnext_words\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m' '\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindices_word\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mind\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mind\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnext_indices\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m             \u001b[0msentence\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m' '\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m' '\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mSTEP\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m \u001b[1;34m' '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[0mnext_words\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m             \u001b[1;31m#print('After appending next word the sentence is: {}'.format(sentence))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'numpy.int64' object is not iterable"
     ]
    }
   ],
   "source": [
    "print_callback = LambdaCallback(on_epoch_end=on_epoch_end)\n",
    "model_history = model.fit(X_ngram, y_ngram, callbacks=[print_callback], epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_model.fit_model(model, words, INPUT_SEQUENCE_LEN, OUTPUT_SEQUENCE_LEN, SentenceGenerator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplots(figsize=(12,12))\n",
    "sns.lineplot(x=range(5),y=model_history.history['acc'])\n",
    "sns.lineplot(x=range(5),y=model_history.history['loss'])\n",
    "plt.legend(labels=['acc','loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                                          "
     ]
    }
   ],
   "source": [
    "sentence = ' '.join(text_seq[0: INPUT_SEQUENCE_LEN])\n",
    "print(sentence)\n",
    "for i in range(0,500, STEP):\n",
    "    x_pred = np.zeros((1, INPUT_SEQUENCE_LEN, len(words)))\n",
    "    for t, word in enumerate(sentence.split(' ')):\n",
    "        x_pred[0, t, word_indices[word]] = 1.\n",
    "    #print('Here the sentence is {}'.format(sentence))\n",
    "\n",
    "    preds = model.predict(x_pred)\n",
    "    next_indices = sample(preds, temperature=18.0)\n",
    "    try:\n",
    "        next_words = ' '.join([indices_word[ind] for ind in next_indices])\n",
    "    except:\n",
    "        next_words = indices_word[next_indices]\n",
    "    sentence = ' '.join(sentence.split(' ')[STEP:])+ ' ' +next_words\n",
    "    #print('After appending next word the sentence is: {}'.format(sentence))\n",
    "    sys.stdout.write(' ' + next_words)\n",
    "    sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = preds[0,i,:]#.astype(dtype='float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_index = random.randint(0, len(text_seq) - INPUT_SEQUENCE_LEN - 1)\n",
    "generated = ''\n",
    "sentence = ' '.join(text_seq[start_index: start_index + INPUT_SEQUENCE_LEN])\n",
    "generated += sentence\n",
    "print('----- Generating with seed: \"' + sentence + '\"')\n",
    "sys.stdout.write(generated)\n",
    "\n",
    "x_pred = np.zeros((1, INPUT_SEQUENCE_LEN, len(words)))\n",
    "for t, word in enumerate(sentence.split(' ')):\n",
    "    x_pred[0, t, word_indices[word]] = 1.\n",
    "y_pred = model.predict(x_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_seq_seq(y_pred, temperature=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,50, STEP):\n",
    "    x_pred = np.zeros((1, INPUT_SEQUENCE_LEN, len(words)))\n",
    "    sentence = ' '.join(sentence)\n",
    "    for t, word in enumerate(sentence.split(' ')):\n",
    "        x_pred[0, t, word_indices[word]] = 1.\n",
    "\n",
    "    preds = model.predict(x_pred)\n",
    "    next_indices = sample_seq_seq(preds)\n",
    "    next_words = ' '.join([indices_word[ind] for ind in next_indices])\n",
    "\n",
    "    sentence = ' '.join(sentence.split(' ')[1:]) + ' ' +next_words\n",
    "    \n",
    "    sys.stdout.write(' ' + next_words)\n",
    "    sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(model.predict(x_pred), axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.multinomial(1, model.predict(x_pred)[1:1:],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "' '.join(['Blah']) + ' ' + '3rd_blah'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
